{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "def _doThresholdOut(acc1,acc2):\n",
    "    scoreDiff = np.abs(acc1-acc2)\n",
    "    threshNoise = tolerance*np.random.randn(1)\n",
    "    if scoreDiff<(threshold+threshNoise):\n",
    "        correctedAcc = np.copy(acc1)\n",
    "    else:\n",
    "        correctedAcc = np.copy(acc2)+tolerance*np.random.randn(1)\n",
    "        correctedAcc = correctedAcc[0]\n",
    "    return correctedAcc\n",
    "\n",
    "def getThresholdoutAccy(model,X1,y1,X2,y2,X3,y3,featToUse):\n",
    "    \"\"\"\n",
    "    This is the the method for measuring the accuracy\n",
    "    of the model on the training data, the test data,\n",
    "    and using the thresholdout to estimate the 'real'\n",
    "    accuracy that wont be biased by the fact we've\n",
    "    reused information from the holdout set to adaptively\n",
    "    select features to use\n",
    "    \"\"\"\n",
    "    \n",
    "    # fitting models to each half of the data and\n",
    "    # getting in- and out-of sample accuracies\n",
    "    model1 = model.fit(X1[:,featToUse],y1)\n",
    "    inSampAcc_model1  = model1.score(X1[:,featToUse],y1)\n",
    "    outSampAcc_model1 = model1.score(X2[:,featToUse],y2)\n",
    "    testAcc = model1.score(X3[:,featToUse],y3)\n",
    "    \n",
    "    #model2 = model.fit(X2[:,featToUse],y2)\n",
    "    #inSampAcc_model2  = model2.score(X2[:,featToUse],y2)\n",
    "    #outSampAcc_model2 = model2.score(X1[:,featToUse],y1)\n",
    "    \n",
    "    inSampAcc  = inSampAcc_model1 #( inSampAcc_model1 + inSampAcc_model2)/2\n",
    "    outSampAcc = outSampAcc_model1 #(outSampAcc_model1 +outSampAcc_model2)/2\n",
    "    \n",
    "    # using threshold out to estimate a 'real' performance\n",
    "    # score that's unbiased by reused holdout samples\n",
    "    correctedAcc = _doThresholdOut(inSampAcc,outSampAcc)\n",
    "    \n",
    "    return inSampAcc,outSampAcc,correctedAcc,testAcc\n",
    "\n",
    "def _thresholdFeatures(c):\n",
    "    \"\"\"\n",
    "    This function sets strong positive features to 1\n",
    "    and strong negative features to -1\n",
    "    \"\"\"\n",
    "    cutoff = 1.0*np.sqrt(np.mean(c**2))\n",
    "    cThresh = np.zeros(c.shape)\n",
    "    cThresh[c>cutoff]  =  1.0\n",
    "    cThresh[c<-cutoff] = -1.0\n",
    "    return cThresh\n",
    "\n",
    "\n",
    "def adaptiveRankFeatureImportance(trainX,trainY,holdoutX,holdoutY):\n",
    "    \"\"\"\n",
    "    This function takes in the train/holdout sets\n",
    "    and ranks the strength of each feature\n",
    "    \"\"\"\n",
    "    trainCoeff   = model.fit(trainX,trainY).coef_.ravel()\n",
    "    holdoutCoeff = model.fit(holdoutX,holdoutY).coef_.ravel()\n",
    "    \n",
    "    trainThresh = _thresholdFeatures(trainCoeff)\n",
    "    holdoutThresh = _thresholdFeatures(holdoutCoeff)\n",
    "    \n",
    "    goodFeat = trainThresh==holdoutThresh\n",
    "    maskedTrainX = trainX*goodFeat.astype('float')\n",
    "    trainCoeff2  = model.fit(maskedTrainX,trainY).coef_.ravel()\n",
    "    featureRank = list(np.argsort(np.abs(trainCoeff2)))\n",
    "    return featureRank\n",
    "\n",
    "\"\"\"\n",
    "    #find where features are the same sign across trials\n",
    "    tmp1 = _thresholdFeatures(trainCoeff)\n",
    "    tmp2 = _thresholdFeatures(holdoutCoeff)\n",
    "    matchingSigns = tmp1*tmp2\n",
    "    \n",
    "    # sort the same-signed trials by their strength during training\n",
    "    featureRank = list(np.argsort(np.abs(trainCoeff)*matchingSigns))\n",
    "    return featureRank\n",
    "\"\"\"\n",
    "\n",
    "def makeRandomData(n,d,numInform,isClassification=False):\n",
    "    \"\"\"\n",
    "    Make random data for training/holdout\n",
    "    sets and a completely fresh 'test' set\n",
    "    for validation\n",
    "    \"\"\"\n",
    "    fullX = np.random.rand(3*n,d)\n",
    "    fullY = zscore(np.random.rand(3*n,))\n",
    "    snr = 1/(numInform)\n",
    "    for i in range(numInform):\n",
    "        fullX[:,i] = fullX[:,i]+snr*fullY\n",
    "    fullX = zscore(fullX,axis=0)\n",
    "    #fullX,fullY = make_regression(n_samples=3*n, n_features=d, \\\n",
    "    #                          n_informative=numInform, \\\n",
    "    #                          n_targets=1,noise=250)\n",
    "    \n",
    "    if isClassification:\n",
    "        fullY = fullY>np.median(fullY)\n",
    "    \n",
    "    trainX = fullX[0::3,:]\n",
    "    holdoutX  = fullX[1::3,:]\n",
    "    testX  = fullX[2::3,:]\n",
    "    \n",
    "    trainY = fullY[0::3].ravel()\n",
    "    holdoutY = fullY[1::3].ravel()\n",
    "    testY  = fullY[2::3].ravel()\n",
    "    return trainX,trainY,holdoutX,holdoutY,testX,testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numInform = 10\n",
    "kList = range(1,50)\n",
    "numPerm = 30\n",
    "\n",
    "n = 500\n",
    "d = 1000\n",
    "\n",
    "threshold= 0.01\n",
    "tolerance = (threshold/4.0)\n",
    "\n",
    "isClsf = False\n",
    "\n",
    "if isClsf:\n",
    "    model = LogisticRegression(penalty='l2',C=1.0)\n",
    "else:\n",
    "    model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing how tresholdout works when there's a signal in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelPerformance = pd.DataFrame(data=[],columns=['perm','numFeat','perf','dset'])\n",
    "\n",
    "for p in range(numPerm):\n",
    "    \n",
    "    # Make random data for this perm\n",
    "    trainX,trainY, holdoutX,holdoutY, \\\n",
    "    testX,testY = makeRandomData(n,d,numInform,isClassification=isClsf)\n",
    "    \n",
    "    # Rank the importance of every feature in a way that\n",
    "    # combines adaptive feedback from the holdout set\n",
    "    featureRank = adaptiveRankFeatureImportance(trainX,trainY,holdoutX,holdoutY)\n",
    "\n",
    "    # Measure performance as a function of\n",
    "    # how many features are retained\n",
    "    for key,numFeat in enumerate(kList):\n",
    "        featToUse = featureRank[-numFeat:]\n",
    "        t1,t2,t3,t4 = getThresholdoutAccy(model, \\\n",
    "                        trainX, trainY, \\\n",
    "                        holdoutX,holdoutY, \\\n",
    "                        testX,testY, \\\n",
    "                        featToUse)\n",
    "        newRowsDict = {'perm':p,'numFeat':numFeat, \\\n",
    "                       'perf':[t1,t2,t3,t4], \\\n",
    "                       'dset':['trainPerf','testPerf','thresholdout','fresh']}\n",
    "        newRow = pd.DataFrame.from_dict(newRowsDict)\n",
    "        modelPerformance = pd.concat([modelPerformance,newRow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.figure();\n",
    "sb.set_style('whitegrid');\n",
    "sb.tsplot(data=modelPerformance,time='numFeat',unit='perm',condition='dset',value='perf');\n",
    "plt.title('Real');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing how thresholdout works when there's no effect in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelPerformanceRAND = pd.DataFrame(data=[],columns=['perm','numFeat','perf','dset'])\n",
    "\n",
    "for p in range(numPerm):\n",
    "    # Make random data for this perm\n",
    "    trainX,trainY, holdoutX,holdoutY, \\\n",
    "    testX,testY = makeRandomData(n,d,numInform,isClassification=isClsf)\n",
    "    \n",
    "    # Ensuring that there's no effect in the data\n",
    "    # by permuting the X-to-y pairing\n",
    "    np.random.shuffle(trainY)\n",
    "    np.random.shuffle(holdoutY)\n",
    "    np.random.shuffle(testY)\n",
    "    \n",
    "    # Rank the importance of every feature in a way that\n",
    "    # combines adaptive feedback from the holdout set\n",
    "    featureRank = adaptiveRankFeatureImportance(trainX,trainY,holdoutX,holdoutY)\n",
    "    \n",
    "    for key,numFeat in enumerate(kList):\n",
    "        featToUse = featureRank[-numFeat:]\n",
    "        t1,t2,t3,t4 = getThresholdoutAccy(model, \\\n",
    "                        trainX, trainY, \\\n",
    "                        holdoutX,holdoutY, \\\n",
    "                        testX,testY, \\\n",
    "                        featToUse)\n",
    "        newRowsDict = {'perm':p,'numFeat':numFeat, \\\n",
    "                       'perf':[t1,t2,t3,t4], \\\n",
    "                       'dset':['trainPerf','testPerf','thresholdout','fresh']}\n",
    "        newRow = pd.DataFrame.from_dict(newRowsDict)\n",
    "        modelPerformanceRAND = pd.concat([modelPerformanceRAND,newRow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.figure();\n",
    "sb.set_style('whitegrid');\n",
    "sb.tsplot(data=modelPerformanceRAND,time='numFeat',unit='perm',condition='dset',value='perf');\n",
    "plt.title('Random');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
