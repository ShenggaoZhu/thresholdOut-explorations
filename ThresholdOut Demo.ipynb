{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "def _doThresholdOut(p1, p2):\n",
    "    scoreDiff = np.abs(p1 - p2)\n",
    "    threshNoise = tolerance * np.random.randn(1)\n",
    "    if scoreDiff < (threshold + threshNoise):\n",
    "        correctedAcc = np.copy(p1)\n",
    "    else:\n",
    "        correctedAcc = np.copy(p2) + tolerance * np.random.randn(1)\n",
    "        correctedAcc = correctedAcc[0]\n",
    "    return correctedAcc\n",
    "\n",
    "def getThresholdoutAccy(model, featToUse, X1, y1, X2, y2, X3, y3):\n",
    "    \"\"\"\n",
    "    This is the the method for measuring the accuracy\n",
    "    of the model on the training data, the test data,\n",
    "    and using the thresholdout to estimate the 'real'\n",
    "    accuracy that wont be biased by the fact we've\n",
    "    reused information from the holdout set to adaptively\n",
    "    select features to use\n",
    "    \"\"\"\n",
    "    \n",
    "    # fitting models to each half of the data and\n",
    "    # getting in- and out-of sample accuracies\n",
    "    model1 = model.fit(X1[:, featToUse], y1)\n",
    "    inSampAcc_model1  = model1.score(X1[:, featToUse], y1)\n",
    "    outSampAcc_model1 = model1.score(X2[:, featToUse], y2)\n",
    "    testAcc = model1.score(X3[:, featToUse], y3)\n",
    "    \n",
    "    #model2 = model.fit(X2[:,featToUse],y2)\n",
    "    #inSampAcc_model2  = model2.score(X2[:,featToUse],y2)\n",
    "    #outSampAcc_model2 = model2.score(X1[:,featToUse],y1)\n",
    "    \n",
    "    inSampAcc  = inSampAcc_model1 #( inSampAcc_model1 + inSampAcc_model2)/2\n",
    "    outSampAcc = outSampAcc_model1 #(outSampAcc_model1 +outSampAcc_model2)/2\n",
    "    \n",
    "    # using threshold out to estimate a 'real' performance\n",
    "    # score that's unbiased by reused holdout samples\n",
    "    correctedAcc = _doThresholdOut(inSampAcc, outSampAcc)\n",
    "    \n",
    "    return inSampAcc, outSampAcc, correctedAcc, testAcc\n",
    "\n",
    "\n",
    "def _thresholdFeatures(c):\n",
    "    \"\"\"\n",
    "    This function sets strong positive features to 1\n",
    "    and strong negative features to -1\n",
    "    \"\"\"\n",
    "    cutoff = 1.0 * np.sqrt(np.mean(c**2))\n",
    "    cThresh = np.zeros(c.shape)\n",
    "    cThresh[c > cutoff]  =  1.0\n",
    "    cThresh[c < -cutoff] = -1.0\n",
    "    return cThresh\n",
    "\n",
    "\n",
    "def adaptiveRankFeatureImportance(trainX, trainY, holdoutX, holdoutY):\n",
    "    \"\"\"\n",
    "    This function takes in the train/holdout sets\n",
    "    and ranks the strength of each feature\n",
    "    \"\"\"\n",
    "    trainCoeff   = model.fit(trainX, trainY).coef_.ravel()\n",
    "    holdoutCoeff = model.fit(holdoutX, holdoutY).coef_.ravel()\n",
    "    #trainThresh = _thresholdFeatures(trainCoeff)\n",
    "    #holdoutThresh = _thresholdFeatures(holdoutCoeff)\n",
    "    #goodFeat = (trainThresh * holdoutThresh) > 0\n",
    "    #maskedTrainFeat = trainThresh * goodFeat.astype('float')\n",
    "    \n",
    "    meanCoeff = trainCoeff + holdoutCoeff\n",
    "    maskedTrainFeat = meanCoeff**2\n",
    "    \n",
    "    featureRank = list(np.argsort(np.abs(maskedTrainFeat)))\n",
    "    return featureRank\n",
    "\n",
    "def makeRandomData(n, d, numInform, isClassification=False):\n",
    "    \"\"\"\n",
    "    Make random data for training/holdout\n",
    "    sets and a completely fresh 'test' set\n",
    "    for validation\n",
    "    \"\"\"\n",
    "    fullX = np.random.randn(3 * n, d)\n",
    "    fullY = np.random.randn(3 * n,)\n",
    "    snr = 1.5 / (numInform)\n",
    "    for i in range(numInform):\n",
    "        fullX[:, i] = (1 - snr) * fullX[:, i] + snr * fullY\n",
    "    \n",
    "    # Turn Y variable into boolean if you\n",
    "    # want classification, otherwise it's\n",
    "    # continuous to allow for regression\n",
    "    if isClassification:\n",
    "        fullY = fullY > np.median(fullY)\n",
    "    \n",
    "    trainX = fullX[0::3, :]\n",
    "    holdoutX  = fullX[1::3, :]\n",
    "    testX  = fullX[2::3, :]\n",
    "    \n",
    "    trainY = fullY[0::3].ravel()\n",
    "    holdoutY = fullY[1::3].ravel()\n",
    "    testY  = fullY[2::3].ravel()\n",
    "    return trainX, trainY, holdoutX, holdoutY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numInform = 10\n",
    "kList = range(1, 30)\n",
    "numPerm = 10\n",
    "\n",
    "n = 200\n",
    "d = 100\n",
    "\n",
    "threshold= 0.01\n",
    "tolerance = (threshold / 4.0)\n",
    "\n",
    "isClsf = True\n",
    "\n",
    "if isClsf:\n",
    "    model = LogisticRegression(penalty='l2', C=1.0)\n",
    "else:\n",
    "    model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing how tresholdout works when there's a signal in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelPerformance = pd.DataFrame(data=[], columns=['perm', 'numFeat', 'perf', 'dset'])\n",
    "\n",
    "for p in range(numPerm):\n",
    "    \n",
    "    # Make random data for this perm\n",
    "    simulatedData = list(makeRandomData(n, d, numInform, isClassification=isClsf))\n",
    "    \n",
    "    # Rank the importance of every feature in a way that\n",
    "    # combines adaptive feedback from the holdout set\n",
    "    featureRank = adaptiveRankFeatureImportance(*simulatedData[:-2])\n",
    "\n",
    "    # Measure performance as a function of\n",
    "    # how many features are retained\n",
    "    for key, numFeat in enumerate(kList):\n",
    "        featToUse = featureRank[-numFeat:]\n",
    "        \n",
    "        output = list(getThresholdoutAccy(model, featToUse, *simulatedData))\n",
    "        \n",
    "        newRowsDict = {'perm': p,\n",
    "                       'numFeat': numFeat,\n",
    "                       'perf': output,\n",
    "                       'dset': ['trainPerf', 'testPerf', 'thresholdout', 'fresh']}\n",
    "        newRow = pd.DataFrame.from_dict(newRowsDict)\n",
    "        modelPerformance = pd.concat([modelPerformance, newRow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/__init__.py:892: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.figure();\n",
    "sb.set_style('whitegrid');\n",
    "sb.tsplot(data=modelPerformance,\n",
    "          time='numFeat',\n",
    "          unit='perm',\n",
    "          condition='dset',\n",
    "          value='perf');\n",
    "plt.title('Real');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing how thresholdout works when there's no effect in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelPerformanceRAND = pd.DataFrame(data=[], columns=['perm', 'numFeat', 'perf', 'dset'])\n",
    "\n",
    "for p in range(numPerm):\n",
    "    # Make random data for this perm\n",
    "    simulatedData = list(makeRandomData(n, d, numInform, isClassification=isClsf))\n",
    "    \n",
    "    # Ensuring that there's no effect in the data\n",
    "    # by permuting the X-to-y pairing\n",
    "    for i in [1, 3, 5]:\n",
    "        np.random.shuffle(simulatedData[i])\n",
    "    \n",
    "    # Rank the importance of every feature in a way that\n",
    "    # combines adaptive feedback from the holdout set\n",
    "    featureRank = adaptiveRankFeatureImportance(*simulatedData[:-2])\n",
    "    \n",
    "    for key,numFeat in enumerate(kList):\n",
    "        featToUse = featureRank[-numFeat:]\n",
    "        output = list(getThresholdoutAccy(model, featToUse, *simulatedData))\n",
    "        \n",
    "        newRowsDict = {'perm': p,\n",
    "                       'numFeat': numFeat,\n",
    "                       'perf': output,\n",
    "                       'dset': ['trainPerf', 'testPerf', 'thresholdout', 'fresh']}\n",
    "        newRow = pd.DataFrame.from_dict(newRowsDict)\n",
    "        modelPerformanceRAND = pd.concat([modelPerformanceRAND, newRow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/__init__.py:892: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.figure();\n",
    "sb.set_style('whitegrid');\n",
    "sb.tsplot(data=modelPerformanceRAND,\n",
    "          time='numFeat',\n",
    "          unit='perm',\n",
    "          condition='dset',\n",
    "          value='perf');\n",
    "plt.title('Random');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
